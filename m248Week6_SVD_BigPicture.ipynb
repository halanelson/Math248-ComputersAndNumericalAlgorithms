{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">![image](JMUlogo.png)\n",
    ">\n",
    "> # Math 248 Computers and Numerical Algorithms\n",
    "> # Hala Nelson\n",
    "> # Week 6: Singular Value Decomposition $A=U\\Sigma V^t$: The big picture  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Given a matrix of real numbers, we want to understand the following, depending on our use case:\n",
    "\n",
    "1. If the matrix represents data that we care for, like images, or tabular data, what are the most important components of this matrix (data)?\n",
    "2. Along what important directions is the data mostly spread (directions with most variation in the data)? \n",
    "3. If I think of a matrix $A_{m\\times n}$ as a transformation from the initial space $\\mathbb{R}^n$ to the target space $\\mathbb{R}^m$, what is the effect of this matrix on vectors in $\\mathbb{R}^n$? To which vectors do they get sent to in $\\mathbb{R}^m$?\n",
    "4. What is the effect of this matrix on space itself? Since this is a linear transormation we know there is no space warping, but there is space stretching, squeezing, rotating, reflecting.\n",
    "5. Can we solve the system of linear equations $Ax=b$? What is the best way to go about this? If there is no solution, is there an approximate solution that satisfies our purposes? Notice that here you are looking for the vector $x$ that gets transformed to $b$ when you act on it with $A$.\n",
    "\n",
    "The singular value decomposition can be used to answer all the above quesions. The first two questions are intrinsic to the matrix itself, while the second two questions have to do with the effect of multiplying the matrix with vectors (the matrix acts on space and the vectors in this space). The fifth question has to do with the very important problem of solving systems of linear equations and appears in all kinds of applications.\n",
    "\n",
    "So we can investigate a matrix of numbers in two ways: \n",
    "- What are its intrinsic properties? \n",
    "- What are its properties when used as a transformation? \n",
    "\n",
    "These two are related because the matrix's intrinsic properties affect how it acts on vectors or space when applied to those.\n",
    "\n",
    "# There are three ways to multiply two matrices $A_{m\\times n}$ and $B_{n\\times s}$ together:\n",
    "\n",
    "1. ## Row-column approach: \n",
    "\n",
    "Produce one entry $(ab)_{ij}$ at a time by taking the dot product of the i'th row from A with the j'th column from B:\n",
    "\n",
    "$$(ab)_{ij}=\\sum_{k=1}^n a_{ik}b_{kj}$$\n",
    "\n",
    "2. ## Column-columns approach: \n",
    "\n",
    "Produce one column $(AB)_{l}$ at a time by linearly combining the columns of $A$ with the entries in the columns of $B$:\n",
    "\n",
    "$$(AB)_l=b_{1l}A_1+b_{2l}A_2+\\dots +b_{nl}A_n$$\n",
    "\n",
    "3. ## Column-row approach: \n",
    "\n",
    "Produce rank one pieces of the product one at a time by multiplying a column of $A$ with the corresponding row of $B$, then add all these rank one matrices together to get the final product $AB$:\n",
    "\n",
    "$$AB=A_1B^r_1+A_2B^r_2+\\dots+A_nB^r_n$$\n",
    "where $A_l$ is the $l$th column of $A$ and $B^r_l$ is the $l$th row of $B$.\n",
    "\n",
    "## Multiplying by a diagonal matrix $\\Sigma$:\n",
    "\n",
    "1. If you multiply $A$ by $\\Sigma$ from the right $A\\Sigma$ then you scale the columns of $A$ by the $\\sigma$'s.\n",
    "2. If you multiply $A$ by $\\Sigma$ from the left $\\Sigma A$ then you scale the rows of $A$ by the $\\sigma$'s.\n",
    "\n",
    "# Because of the singular value decomposition, any matrix A can be expressed as sum one rank one matrices with decreasing order of importance\n",
    "\n",
    "$A=U\\Sigma V^t$: Using the column-row method to multiply matrices, we can expand this product using the sum of rank one matrices method to multiply $U\\Sigma$ with $V^t$ (note that $U\\Sigma$ scales each colum $U_i$ of $U$ by $\\sigma_i$):\n",
    "\n",
    "$$A=U\\Sigma V^t=\\sigma_1U_1V_1^t+\\sigma_2U_2V_2^t+\\dots+\\sigma_rU_rV_r^t$$\n",
    "where $r$ is the rank of the matrix $A$. The great thing about this expression is that it splits $A$ into a sum of rank one matrices arranged according to their order of importance. Moreover, it provides a straightforward way to approximate $A$ by lower rank matrices by setting lower sigular values to zero.\n",
    "\n",
    "\n",
    "# The ingredients of the singular value decomposition of $A=U\\Sigma V^t$:\n",
    "\n",
    "1. The columns of $V$ are the orthonormal eigenvectors of the symmetric matrix $A^tA$\n",
    "2. The columns of $U$ are the orthonormal eigenvectors of the symmetric matrix $AA^t$\n",
    "3. The singular values $\\sigma_1$, $\\sigma_2$, $\\dots$ $\\sigma_r$ are the square roots of the eigenvalues of $A^tA$ or $AA^t$. The singular values are non-negative and arranged in decreasing order. The matrix could have zero singular values.\n",
    "4. Recall $Av_i=\\sigma_i u_i$\n",
    "\n",
    "> **Note**: Every real symmetric positive semi-definite (non-negative eigenvalues) matrix is diagonalizable $S=PDP^{-1}$. $A^tA$ and $AA^t$ happen to both be symmetric positive semi-definite (meaning their eigenvalues are non-negative). \n",
    "\n",
    "# You must always remember the following properties:\n",
    "\n",
    "1.  $A$ sends the special orthonormal vectors $v_i$ of its initial space to scalar multiples of the special orthonormal vectors $u_i$ of its target space: $$Av_i=\\sigma_i u_i$$\n",
    "\n",
    "2. **Determinant of a square matrix**: If your matrix is square, then its determinant is equal to the product of all its singular values: $\\sigma_1\\sigma_2\\dots\\sigma_r$.\n",
    "\n",
    "3. The **condition number** of a matrix (with respect to the $l^2$ norm= usual distance in Euclidean space) is the ratio of the largest singular value to the smallest singular value:\n",
    "$$\\kappa=\\frac{\\sigma_1}{\\sigma_r}.$$\n",
    "\n",
    "**The condition number of a matrix is very important for computational stability:**\n",
    "\n",
    "- It measures how much $A$ stretches space. If the condition number is too large, then it stretches space too much in one direction relative to another direction, and it could be dangerous to do computations in such an extremely stretched space: Solving $Ax=b$ when $A$ has a large condition number will make the solution $x$ unstable in the sense that it is extremely sensitive to perturbations in $b$. A small error in $b$ will result in a solution $x$ that is wildly different than the solution without the error in $b$. It is easy to envision this instability geometrically.\n",
    "\n",
    "- One thing about a matrix with a large condition number: It stretches space too much that it almost collapses it into a space of lower dimension. The inetresting part is that if you decide to throw away that very small singular value and hence work in the collapsed space of lower dimension, your computations become perfectly fine. So at the boundaries of extremeness lies normalcy, except in a lower dimension. \n",
    "\n",
    "- Many iterative numerical methods, including the very useful gradient descent, have matrices involved in their analysis. If the condition number of these matrices is too large, then the iterative method might not converge to a solution. The condition number controls how fast these iterative methods converge. \n",
    "\n",
    "- So numerically solving $Ax=b$ (say by Gaussian Elimination) and iterative methods work fine when the involved matrices have reasonable (not very large) condition numbers.\n",
    "\n",
    "# Using the singular value decomposition to 'invert' *any* matrix through the pseudo-inverse:\n",
    "\n",
    "Since any matrix has a singular value decomposition, we can define the pseudo-inverse $$A=U\\Sigma V^t$$ $$A^+=V\\Sigma^+U^t,$$ where $\\Sigma^+$ is obtained from $\\Sigma$ by inverting all its diagonal entries except for the ones which are zero (or very close to zero if the matrix happens to be ill-conditioned).\n",
    "\n",
    "This allows us to find 'solutions' to *any* system of linear equation $Ax=b$, namely $x=A^+b$. \n",
    "\n",
    "> **Note** The pseudo-inverse of a matrix that has shape $4\\times 2$ would be a matrix of shape $2\\times 4$. Think of it this way: If a matrix sends two dimensional vectors to four dimensional vectors, then its pseudo-inverse would send four dimensional vectors to two dimensional ones.\n",
    "\n",
    "> **Note** The pseudo-inverse of a matrix coincides with its inverse when the inverse exists.\n",
    "\n",
    "# It is important to learn more about symmetric matrices to be able to understand the ingredients of the singular value decomposition. This will also help us understand the difference between the sigular value decomposition $A=U\\Sigma V^t$ and the eigenvalue decomposition $A=PDP^{-1}$ when the latter exists. \n",
    "\n",
    "> **Note** The Singular Value Decomposition always exists, but the eigenvalue decomposition exists only for special matrices, called diagonalizable. Also rectangular matrices are never diagonalizable. When the matrix is diagonalizable, the SVD and the eigenvalue decomposition are NOT EQUAL, unless the matrix is symmetric and has non-negative eigenvalues. \n",
    "\n",
    "1. The best and easiest matrices are square diagonal matrices with the same number along the diagonal.\n",
    "2. The second best ones are square diagonal matrices $D$ that don't necessarily have the same numbers along the diagonal.\n",
    "3. The third best matrices are symmetric matrices. These have real eigenvalues and orthogonal eigenvectors. They are the next closest type of matrices to diagonal matrices, in the sense that they are diagonalizable $S=PDP^{-1}$, or similar to a diagonal matrix after a change in basis. The columns of $P$ (eigenvectors) are orthogonal.   \n",
    "4. The fourth best matrices are square matrices that are diagonalizable $A=PDP^{-1}$. These are similar to a diagonal matrix after a change of basis, however, the columns of $P$ (eigenvectors) need not be orthogonal. \n",
    "5. The fifth best matrices are all the rest. These are not diagonalizable, meaning there is no change of basis that can turn them diagonal, however, there is the next closest approach to making them similar to a diagonal matrix, via the singular value decomposition $A=U\\Sigma V^t$. Here $U$ and $V$ are different than each other, and they have orthonormal columns and rows. Their inverse is very easy, since it is the same as their transpose. The singular value decomposition works for both square and non-square matrices. \n",
    "6. For any matrix $A$, $A^tA$ and $AA^t$ happen to both be symmetric positive semi-definite (meaning their eigenvalues are non-negative), so they are diagonalizable with two bases of orthogonal eigenvectors. When we divide by the norm of these orthogonal eigenvectors they become orthonormal. These will be the columns of $V$ and of $U$ respectively. $A^tA$ and $AA^t$ have exactly the same nonnegative eigenvalues, $\\lambda_i=\\sigma_i^2$. Arrange these in decreasing order (keeping the corresponding eigenvector order in $U$ and $V$), and we get the diagonal matrix $\\Sigma$ in the singular value decomposition.\n",
    "7. **What if the matrix we start with is symmetric? How is its singular value decomposition $A=U\\Sigma V^t$ related to its diagonalization $A=PDP^{-1}$**? \n",
    "\n",
    "* The columns of $P$, which are the eigenvectors of symmetric $A$ are orthogonal. When you divide by their lengths, they become orthonormal. Stack these orthonormal eigenvectors vectors in a matrix in the order corresponding to decreasing absolute value of the eigenvalues and you get both the $U$ and the $V$ for the singular value decomposition. \n",
    "\n",
    "* Now if all the eigenvalues of symmetric $A$ happen to be nonnegative, the singular value decomposition of this positive semi-definite symmetric matrix will be the same as its eigenvalue decomposition, provided you normalize the orthogonal eigenvectors in $P$, order them with respect to the nonnegative eigenvalues in decreasing order. So $U=V$ in this case. \n",
    "\n",
    "* What if some (or all) of the eigenvalues are negative? Then the singular values $\\sigma_i=|\\lambda_i|=-\\lambda_i$, but now you have to be careful with the corresponding eigenvectors $Av_i=-\\lambda_i v_i=\\lambda_i(-v_i)=\\sigma_iu_i$. This makes $U$ and $V$ in the singular value decomposition unequal. So the singular value decomposition of a symmetric matrix that has some negative eigenvalues can be easily extracted from its eigenvalue decomposition, but it is not exactly the same.\n",
    "\n",
    "8. **What if the matrix we start with is not symmteric but diagonalizable? How is its singular value decomposition $A=U\\Sigma V^t$ related to its diagonalization $A=PDP^{-1}$**? The eigenvectors of $A$, which are the columns of $P$ are in general not orthogonal in this case, so the singular value decomposition and the eigenvalue decomposition of such a matrix are not related.\n",
    "\n",
    "# The singular value decomposition is extremely important in Data Science, Machine Learning, and Artificial Intelligence, for example, it is the mathematics behind principal component analysis and latent semantic analysis.\n",
    "\n",
    "# How do Python and others numerically calculate the SVD of a matrix?\n",
    "\n",
    "In theory, calculating the SVD for a general matrix or the eigenvalues and eigenvectors for a square matrix requires solving for the eigenvalues (setting a polynomial=0), then solving a linear system of equations to obtain the eigenvectors. This is very far from being applicable in practice, since the problem of finding the zeros of a polynomial is very sensitive to the variations in the coefficients of the polynomials, so the computational problem becomes very prone to round off errors that are present in the coefficients. We need numerical methods that find the eigenvectors and eigenvalues without having to numerically compute the zeros of a polynomial. We also need to be careful solving a linear system of equations. We need a stable method, or if we use Gaussian elimination ($LU$ decomposition), we need to be careful that the matrix is well conditioned.\n",
    "\n",
    "# One easy numerical way to obtain eigenvectors of a square matrix\n",
    "\n",
    "An eigenvector of a square matrix $A$ is a nonzero vector that does not change its direction when multiplied by $A$, it just gets scaled by an eigenvalue $\\lambda$:\n",
    "$$Av=\\lambda v.$$\n",
    "\n",
    "Here is an easy numerical algorithm to find an eigenvector of a matrix (the eigenvector it will find is the one corresponding to the largest eigenvalue. So this algorithm catches the direction that gets stretched the most, but not the others):\n",
    "1. Start at a random unit vector $v_0$\n",
    "2. Multiply by $A$: $v_{i+1}=Av_i$\n",
    "3. Divide by the length of $v_{i+1}$ to avoid the size of your vectors growing too large.\n",
    "3. Stop when you converge.\n",
    "\n",
    "The above iterative method is very simple but has a drawback: It only finds one eigenvector of the matrix, the eigenvector corresponding to its largest eigenvalue. So it finds the direction that gets stretched the most when you apply $A$.\n",
    "\n",
    "In general, Python uses a mechanism called Housholder reflections and the $QR$ decomposition of a matrix to compute its full eigenvector decomposition (full spectrum). Recall that to compute the SVD we must find the eigenvectors and eigenvalues of $A^tA$ and $AA^t$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Iterative algorithm to compute the eigenvector of a matrix corresponding to its largest eigenvalue.\n",
    "\n",
    "This algorithm catches only one eigenvector, in the direction that gets stretched the most, but not the other eigenvectors:\n",
    "\n",
    "Consider the matrix $A=\\begin{pmatrix}1&2\\\\2&-3\\end{pmatrix}$\n",
    "\n",
    "1. Start at a random unit vector $v_0$ (make sure your vector has length $1$). \n",
    "2. Multiply by $A$: $v_{i+1}=Av_i$\n",
    "3. Divide by the length of $v_{i+1}$ to avoid the size of your vectors growing too large with all the multiplications by $A$.\n",
    "3. Stop when you converge (you can run this for like 20 times and see if the vector is changing or not).\n",
    "4. Make a plot that shows the subsequent transformations of your vector until you converge.\n",
    "\n",
    "The above iterative method is very simple but has a drawback: It only finds one eigenvector of the matrix, the eigenvector corresponding to its largest eigenvalue. So it finds the direction that gets stretched the most when you apply $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0]\n",
      "[0.4472136  0.89442719]\n",
      "[ 0.78086881 -0.62469505]\n",
      "[-0.1351132   0.99083017]\n",
      "[ 0.49483862 -0.86898489]\n",
      "[-0.3266748  0.9451368]\n",
      "[ 0.40898444 -0.91254136]\n",
      "[-0.37000749  0.92902877]\n",
      "[ 0.38871252 -0.92135909]\n",
      "[-0.37979817  0.92506937]\n",
      "[ 0.3840601 -0.9233081]\n",
      "[-0.38202565  0.92415172]\n",
      "[ 0.38299752 -0.92374937]\n",
      "[-0.38253341  0.92394166]\n",
      "[ 0.38275508 -0.92384985]\n",
      "[-0.38264921  0.92389371]\n",
      "[ 0.38269977 -0.92387276]\n",
      "[-0.38267563  0.92388277]\n",
      "[ 0.38268716 -0.92387799]\n",
      "[-0.38268165  0.92388027]\n",
      "[ 0.38268428 -0.92387918]\n",
      "[-0.38268303  0.9238797 ]\n",
      "[ 0.38268363 -0.92387945]\n",
      "[-0.38268334  0.92387957]\n",
      "[ 0.38268348 -0.92387951]\n",
      "[-0.38268341  0.92387954]\n",
      "[ 0.38268344 -0.92387953]\n",
      "[-0.38268343  0.92387953]\n",
      "[ 0.38268343 -0.92387953]\n",
      "\n",
      " v= [-0.38268343  0.92387953]\n",
      "Av= [ 1.46507563 -3.53700546]\n",
      "$\\lambda=$ -3.828427140993716\n",
      "$\\lambda=$ -3.8284271219585553\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set the figure\n",
    "plt.plot(figsize=(20,20))\n",
    "plt.axis('scaled')\n",
    "plt.xlim(-2,2)\n",
    "plt.ylim(-2,2)\n",
    "plt.title('''Start at $v=[1,0]$, \n",
    "then multiply by $A$ \n",
    "and normalize until you converge\n",
    "to an eigenvector''', fontsize=15)\n",
    "\n",
    "# Define A as a numpy array\n",
    "A=np.array([[1,2],[2,-3]])\n",
    "\n",
    "# define v and subsequent multiplications by A\n",
    "v=[1,0]\n",
    "for i in range(1,30):\n",
    "    print(v)\n",
    "    plt.quiver(0,0,v[0],v[1],scale=1,scale_units='xy',angles='xy',color=['b'])\n",
    "    v=A.dot(v)\n",
    "    v=v/np.linalg.norm(v) # normalize the vector: make it of length 1\n",
    "    \n",
    "# Let's find the corresponding eigenvalue for this eigenvector. Recall: Av=lambda*v\n",
    "print('\\n v=',v)\n",
    "print('Av=',A.dot(v))\n",
    "print('$\\lambda=$', A.dot(v)[0]/v[0])\n",
    "print('$\\lambda=$', A.dot(v)[1]/v[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
