{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">![image](JMUlogo.png)\n",
    ">\n",
    "> # Math 248 Computers and Numerical Algorithms\n",
    "> # Hala Nelson\n",
    "> # Week 8: Machine Representation Of Numbers And Resulting Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# These notes are great\n",
    "\n",
    "https://statmath.wu.ac.at/courses/data-analysis/itdtHTML/node55.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many bits (binary digits) does a computer allocate to represent numbers?\n",
    "\n",
    "* Each computer is different (personal computers are different than high performance computers).\n",
    "* Computers treat integers and real numbers differently: They allocate a certain number of bits to represent all integers. They represent real numbers as floating point numbers: 1 bit for the sign, certain bits for the mantissa, and certain bits for the exponent (power of 2). \n",
    "* This means that there is only a finite amount of numbers whether integer or real that can be represented on a machine. Thus any number that we include in our computations that cannot be accurately represented (because there are not enough allocated bits) will introduce errors into our computations. These errors are called round-off errors and they will accumulate if we keep using the in-accurately represented numbers in our iterations, etc.\n",
    "* Because there are only finitely many bits that are used to represent integers and real numbers, there are a largest and smallest integers that can be represented, and a largest and smallest real numbers that can be represented, and anything above or below these largest magnitude numbers will be returned as a NaN or inf.\n",
    "\n",
    "# Mathematical theory v.s. computational reality\n",
    "\n",
    "**An example**: x**{0.5} versus np.sqrt(x): On some computers, including the CRAY supercomputers of the 1990s, exponentiation using fractional real exponents (in this case 0.5) was exceedingly slow because it made use of table lookups from logarithm tables. Thus, on CRAY machines, the first variant ran 40 times slower than the second! Even though mathematically these are the exact same thing, one approach requires far more computational effort than the other. In programming, be mindful of good, better, and best ways to accomplish a goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addition on computers is not commutative?! Why?! \n",
    "\n",
    "Write a program that adds $1+\\frac{1}{2}+\\frac{1}{3}+\\dots+\\frac{1}{10^6}$ and another one that adds $\\frac{1}{10^6}+\\frac{1}{10^6-1}+\\dots+\\frac{1}{3}+\\frac{1}{2}+1$ and compare the answers. In theory, these two are the same. Computationally, they are not!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.392726722864989\n",
      "14.392726722865772\n"
     ]
    }
   ],
   "source": [
    "sum=0\n",
    "for n in range(1,10**6+1):\n",
    "    sum=sum+1/n\n",
    "print(sum)\n",
    "\n",
    "sum=0\n",
    "for n in range(1,10**6+1):\n",
    "    sum=sum+1/(10**6-n+1)\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These notes will be helpful for our compuations this week\n",
    "\n",
    "- Adding in base two: $(1+1=10)_2$. \n",
    "- Note that $(11111)_2=2^5-1$. This is similar to $999=10^3-1$ and $99999=10^5-1$. \n",
    "- So if we have $d$ binary bits which are all one, then they represent the integer $2^{d}-1$.\n",
    "- $2^d-2^{d-1}=2^{d-1}(2-1)=2^{d-1}$.\n",
    "- $1000=10^3$ in base 10. Similarly $1000=2^3$ in base 2. So 1 and 31 zeros in base two is equal to $2^{31}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing integers on a machine \n",
    "\n",
    "- A machine allocates $d$ binary digits to store an integer. This is the word length for integers, measured in bits or bytes (each byte is 8 bits). Usually, an integer word is 4 bytes or 32 bits. \n",
    "- The largest integer stored on such a machine will be when the first digit is zero (since it is positive) and all the remaining $d-1$ digits are one, which amounts to $2^{d-1}-1$.\n",
    "- Negative integers are stored as $2^d$ complement of their absolute values, so that is the binary representation of: $2^d-|NegativeInteger|$. One advantage of this is the unique representation of zero. Another advantage is the ability to store one extra negative number, namely: $-2^{d-1}$, stored as $2^{d}-|-2^{d-1}|=2^d-2^{d-1}=2^{d-1}$, essentially turning on all the $d-1$ digits plus the first digit for the sign. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing real numbers on a machine: Floating point numbers (all in base 2) \n",
    "Number=$\\pm.1b_2b_3\\dots b_n\\times 2^{c_1 c_2\\dots c_m}$ where $b's$ and $c's$ are zeros or ones. This is analogous scientific notation in base $10$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision (single precision, double precision)\n",
    "This is the number of significant decimal digits accurately represented by the mantissa. So it is $p$ such that $2^n=10^p$ where $n$ is the number of bits assigned for the mantissa.\n",
    "\n",
    "# Underflow and overflow \n",
    "When the exponent is too large or too small to be accurately represented (need more bits for exponent).\n",
    "\n",
    "# Absolute error ($\\delta=|x-\\bar{x}|$) due to approximation of a real number by a floating point number. This quantity is not dimensionless, it has the units of $x$.\n",
    "\n",
    "# Relative error ($\\epsilon=\\frac{|x-\\bar{x}|}{x}$) due to approximation of a real number by a floating point number. This quantity is dimensionless.\n",
    "\n",
    "# Unit round off error or machine epsilon $u$ (depends on the machine)\n",
    "This is the largest relative error that a machine can commit due to approximation of a real number by a floating point number (due to chopping or rounding). A machine that chops can commit twice as much error as a machine that rounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propagation of roundoff error due to arithmetic operations\n",
    "Calculating the error bounds associated with each arithmetic operation. \n",
    "\n",
    "![image](errorsubtract1.JPG)\n",
    "![image](errorsubtract2.JPG)\n",
    "![image](errorsubtract3.JPG)\n",
    "\n",
    "# Catastrophic loss of significance \n",
    "Due to numerically subtracting two numbers very close to each other. How to avoid such a situation? Enter equivalent mathematical formulas that avoid the problematic subtraction.\n",
    "\n",
    "![image](sigloss1.JPG)\n",
    "![image](sigloss2.JPG)\n",
    "![image](sigloss3.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Sochacki Book Pages 19-33.\n",
    "\n",
    "# Explain Problem 9 Sochacki's book (exercise 9 on Chapter 3 page 33).\n",
    "\n",
    "Write a program that produces the results of problem $9$ in chapter 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises (on Quiz for Week 9)\n",
    "\n",
    "1. What is a supercomputer? What is Cray supercomputer? What is the most powerful supercomputer currently present?\n",
    "\n",
    "2. What is the word length (for both integers and floating point numbers) that a supercomputer usually assigns? \n",
    "\n",
    "3. Given a binary machine that reserves $4 bytes$ for an integer (recall that 1 byte=8 bits), find the range of integers that can be represented. How many numbers are those?\n",
    "\n",
    "4. Write the floating point representation for the binary number $0.00011011$ using a $4$-bit mantissa then write the way it will be stored in the machine (use $5$ bit exponent).\n",
    "\n",
    "5. Compute the largest floating point number that Python can represent. Do a google search to check your answer.\n",
    "\n",
    "6. Suppose you are employed to design a digital watch. How many bits will you need to store the time? Justify your answer.\n",
    "\n",
    "7. Suppose $x = (13)_{10}$. What is $fl(x)$ on a binary computer with a 3-bit mantissa and 3-bit exponent?\n",
    "\n",
    "8. Find the precision of real numbers on a computer with a 64-bit word, of which 15 bits are reserved for the exponent.\n",
    "\n",
    "9. How does a single precision type represent the number -285.75?\n",
    "\n",
    "10. Find the absolute and relative round-off errors incurred when $(23)_{10}$ is approximated by a floating point number with a 3-bit mantissa in base-2.\n",
    "\n",
    "11. Express $0.25$ in floating point notation (use  $6$ bit mantissa, and decimal notation for the exponent).\n",
    "\n",
    "12. Suppose you have a binary machine that allows a 3 bit mantissa, and exponents $m=-2, -1, 0, 1, 2$. Compute all the floating point numbers that this machine represents. How would this machine store the real number $e$? What is the relative error?\n",
    "\n",
    "13. Suppose you have a binary machine that allows 4 bit mantissa, and exponents $m=-1, 0, 1$. Compute all the floating point numbers that this machine represents. How would this machine store the real number $e$? What is the relative error?\n",
    "\n",
    "14. Define machine epsilon. \n",
    "\n",
    "15. Consider a machine in base-2 with a 4-bit mantissa and 4-bit exponent. What is the machine epsilon for this machine?\n",
    "\n",
    "16. Calculate the relative round-off error due to approximating $\\left(\\frac{1}{3}\\right)_{10}$ by a floating point number with a $5$ bit mantissa. What is the machine epsilon for such a machine?\n",
    "\n",
    "17. Write a program that manually computes the machine epsilon of your machine in Python. Explain the logic behind this program.\n",
    "\n",
    "18. Research: Provide an example where catastrophic loss of significance occurs.\n",
    "\n",
    "19. Overflow: Give an example when overflow occurs.\n",
    "\n",
    "20. Precision: IEEE specifications for double precision variables use one bit for the sign, 11 bits for the exponent, and 52 bits for the mantissa. What precision does it have? \n",
    "\n",
    "21. Compute the precision of a Cray supercomputer.\n",
    "\n",
    "22. One way of calculating the inverse hyperbolic cosine function is to rewrite it as $\\cosh^{-1}(x)=-\\ln(x-\\sqrt{x^2-1})$. Explain why this is a bad idea for large values of x, then rewrite it in a form that is worth using for large x.\n",
    "\n",
    "23. Explain why numerically calculating $\\ln(x-\\sqrt{x^2-1})$ could result in catastrophic loss of significance, then explain how this problem can be rectified.\n",
    "\n",
    "24. Explain why numerically calculating $\\ln(b-\\sqrt{b^2-10^{-8}})$ could result in catastrophic loss of significance, then explain how this problem can be rectified.\n",
    "\n",
    "25. Compute the precision of a machine with $23$ bit mantissa. Explain the meaning of your answer.\n",
    "\n",
    "26. The sequence $n\\sin\\left(\\frac{1}{n}\\right)$ converges to $1$ as $n\\to\\infty$ (analytical proof: use L'Hospital's rule). Write a program that verifies this result numerically, then discuss your limitation with how large your numerical $n$ could get. What would happen to your limit numerically if $n=10^{17}$ (you don't have to run your program up to $n=10^{17}$ to answer this question)?\n",
    "\n",
    "27. Prove that the relative error resulting from adding two numbers on the machine is less than or equal to $2u$, where $u$ is machine epsilon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7e+308\n",
      "inf\n"
     ]
    }
   ],
   "source": [
    "# Check the largest floating point number in python\n",
    "\n",
    "print(1.7e308)\n",
    "print(1.799e308)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
